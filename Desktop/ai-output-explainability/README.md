# 🧠 AI Output Explainability Tool

This project provides a lightweight tool to evaluate and explain the quality of responses generated by AI language models. It applies rule-based logic to assess sentiment, repetition, keyword coverage, and output length to help developers understand and improve AI-generated responses.

---

## 🔍 Features

- ✅ Sentiment detection (positive/negative/neutral)
- 🔁 Repetition detection
- 🔑 Keyword coverage scoring
- 🔢 Word count analysis
- 📊 Tabular evaluation summary

---

## 💻 Technologies Used

- Python
- textblob
- pandas
- re (regex)

---

## 🚀 How to Use

1. Clone the repository and navigate to the folder:
   ```bash
   git clone git@github.com:YourUsername/ai-output-explainability.git
   cd ai-output-explainability
   ```

2. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. Launch the notebook:
   ```bash
   cd notebook
   jupyter notebook explainability_tool.ipynb
   ```

4. Update the prompt, response, and keyword list to evaluate your own AI outputs.

---

## 📁 Project Structure

```
ai-output-explainability/
├── notebook/
│   └── explainability_tool.ipynb
├── README.md
└── requirements.txt
```

---

## 🧠 Author

**Shrushti Wable**  
[GitHub](https://github.com/ShrushtiCodes)