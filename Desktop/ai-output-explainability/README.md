# ğŸ§  AI Output Explainability Tool

This project provides a lightweight tool to evaluate and explain the quality of responses generated by AI language models. It applies rule-based logic to assess sentiment, repetition, keyword coverage, and output length to help developers understand and improve AI-generated responses.

---

## ğŸ” Features

- âœ… Sentiment detection (positive/negative/neutral)
- ğŸ” Repetition detection
- ğŸ”‘ Keyword coverage scoring
- ğŸ”¢ Word count analysis
- ğŸ“Š Tabular evaluation summary

---

## ğŸ’» Technologies Used

- Python
- textblob
- pandas
- re (regex)

---

## ğŸš€ How to Use

1. Clone the repository and navigate to the folder:
   ```bash
   git clone git@github.com:YourUsername/ai-output-explainability.git
   cd ai-output-explainability
   ```

2. Install required packages:
   ```bash
   pip install -r requirements.txt
   ```

3. Launch the notebook:
   ```bash
   cd notebook
   jupyter notebook explainability_tool.ipynb
   ```

4. Update the prompt, response, and keyword list to evaluate your own AI outputs.

---

## ğŸ“ Project Structure

```
ai-output-explainability/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ explainability_tool.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Author

**Shrushti Wable**  
[GitHub](https://github.com/ShrushtiCodes)